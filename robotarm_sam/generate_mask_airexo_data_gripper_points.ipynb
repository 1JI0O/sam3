{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM3 远程无 GUI 两阶段分割（机械臂 + gripper 新 obj_id）\n",
    "\n",
    "本 notebook 面向远程服务器（无 GUI）逐 cell 交互执行：\n",
    "\n",
    "- 阶段 A：先做一次普通传播（bootstrap）填充缓存，再进行机械臂 points/labels refinement。\n",
    "- 阶段 B：在关键帧使用 points + point_labels + **全新 obj_id** 新增 gripper，再传播。\n",
    "- 导出支持对象集合选择：`arm-only` / `gripper-only` / `union` / `custom`。\n",
    "\n",
    "> 注意：本 notebook 使用 inline 可视化与日志打印，不依赖 `%matplotlib widget`、按钮、鼠标事件回调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce11e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import sam3\n",
    "from sam3.model_builder import build_sam3_video_predictor\n",
    "from sam3.visualization_utils import prepare_masks_for_visualization, visualize_formatted_frame_output\n",
    "\n",
    "plt.rcParams[\"axes.titlesize\"] = 12\n",
    "plt.rcParams[\"figure.titlesize\"] = 12\n",
    "\n",
    "# ==============================\n",
    "# 关键配置区（建议仅修改本区）\n",
    "# ==============================\n",
    "\n",
    "# 1) 路径配置\n",
    "VIDEO_PATH = \"/data/haoxiang/data/airexo2/task_0013/train/scene_0001/cam_105422061350/color\"\n",
    "CHECKPOINT_PATH = \"/data/haoxiang/sam3/models/facebook/sam3/sam3.pt\"\n",
    "\n",
    "# 2) 推理配置\n",
    "CUDA_VISIBLE_DEVICES = \"0,1,2,3\"\n",
    "APPLY_TEMPORAL_DISAMBIGUATION = False\n",
    "PROPAGATION_DIRECTION_STAGE_A = \"forward\"  # 建议 forward\n",
    "PROPAGATION_DIRECTION_STAGE_B = \"forward\"  # 关键帧新增对象后再 forward\n",
    "\n",
    "# 3) 对象 ID 配置（左右机械臂 + 左右 gripper，四者必须互不重复）\n",
    "arm_left_obj_id = 0\n",
    "arm_right_obj_id = 1\n",
    "gripper_left_obj_id = 2\n",
    "gripper_right_obj_id = 3\n",
    "\n",
    "# 4) 阶段 A：左右机械臂 bootstrap 文本提示（可独立配置）\n",
    "# 为避免首次 points add_prompt 触发 cached outputs 断言，需先完成一次普通传播\n",
    "ARM_LEFT_BOOTSTRAP_TEXT_PROMPT = \"\"  # 建议可填，如 \"left robot arm\"\n",
    "ARM_LEFT_BOOTSTRAP_FALLBACK_TEXT_PROMPT = \"left robot arm\"\n",
    "ARM_LEFT_BOOTSTRAP_FRAME_INDEX = None\n",
    "\n",
    "ARM_RIGHT_BOOTSTRAP_TEXT_PROMPT = \"\"  # 建议可填，如 \"right robot arm\"\n",
    "ARM_RIGHT_BOOTSTRAP_FALLBACK_TEXT_PROMPT = \"right robot arm\"\n",
    "ARM_RIGHT_BOOTSTRAP_FRAME_INDEX = None\n",
    "\n",
    "# 5) 阶段 A：左右机械臂 points refinement（可为空，左右独立）\n",
    "# coord_type: \"abs\"(像素坐标) / \"rel\"([0,1]归一化坐标)\n",
    "ARM_LEFT_INITIAL_PROMPTS = [\n",
    "    {\n",
    "        \"frame_index\": 120,\n",
    "        \"obj_id\": 0,\n",
    "        \"coord_type\": \"abs\",\n",
    "        \"points\": [[962, 350]],\n",
    "        \"labels\": [0],\n",
    "    }\n",
    "]\n",
    "\n",
    "ARM_RIGHT_INITIAL_PROMPTS = []\n",
    "\n",
    "# 6) 阶段 B：关键帧新增左右 gripper（points + point_labels + 新 obj_id）\n",
    "# 支持多关键帧，左右 obj_id 可独立配置\n",
    "GRIPPER_LEFT_KEYFRAME_PROMPTS = [\n",
    "    {\n",
    "        \"frame_index\": 120,\n",
    "        \"obj_id\": 2,\n",
    "        \"coord_type\": \"abs\",\n",
    "        \"points\": [[973, 356], [930, 330]],\n",
    "        \"labels\": [1, 0],\n",
    "    }\n",
    "]\n",
    "\n",
    "GRIPPER_RIGHT_KEYFRAME_PROMPTS = []\n",
    "\n",
    "# 6.5) 可视化标注导出接入（仅切换数据来源，不触发推理）\n",
    "# True: Stage A/B 使用 ANNOTATION_EXPORT_PROMPTS\n",
    "# False: Stage A/B 使用手工配置的 *_PROMPTS\n",
    "USE_VISUAL_ANNOTATION_EXPORT = False\n",
    "ANNOTATION_EXPORT_PROMPTS = None\n",
    "\n",
    "# 7) 可视化配置\n",
    "VIS_FRAME_STRIDE = 60\n",
    "VIS_MAX_PLOTS = 8\n",
    "\n",
    "# 8) 导出配置\n",
    "# EXPORT_MODE: \"arm-only\" | \"gripper-only\" | \"union\" | \"custom\"\n",
    "EXPORT_MODE = \"union\"\n",
    "EXPORT_CUSTOM_OBJ_IDS = []\n",
    "EXPORT_OUTPUT_DIR = \"/data/haoxiang/propainter/masks_airexo_arm_gripper_union\"\n",
    "EXPORT_DILATE_RADIUS = 15\n",
    "\n",
    "# 运行时变量（无需手动修改）\n",
    "predictor = None\n",
    "session_id = None\n",
    "video_frames_for_vis = None\n",
    "TOTAL_FRAMES = None\n",
    "IMG_WIDTH = None\n",
    "IMG_HEIGHT = None\n",
    "arm_left_prompts_norm = None\n",
    "arm_right_prompts_norm = None\n",
    "gripper_left_prompts_norm = None\n",
    "gripper_right_prompts_norm = None\n",
    "outputs_stage_a = None\n",
    "outputs_stage_b = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db182c33",
   "metadata": {},
   "source": [
    "## 工具函数（校验 / 坐标转换 / 推理流程 / 导出 / 清理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ebca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_process_group():\n",
    "    if torch.distributed.is_available() and torch.distributed.is_initialized():\n",
    "        try:\n",
    "            torch.distributed.destroy_process_group()\n",
    "            print(\"[cleanup] distributed process group destroyed\")\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] destroy_process_group() failed: {e}\")\n",
    "\n",
    "\n",
    "def cleanup_resources(predictor_obj=None, session_id_value=None):\n",
    "    if predictor_obj is not None and session_id_value is not None:\n",
    "        try:\n",
    "            _ = predictor_obj.handle_request(\n",
    "                request=dict(\n",
    "                    type=\"close_session\",\n",
    "                    session_id=session_id_value,\n",
    "                )\n",
    "            )\n",
    "            print(f\"[cleanup] session closed: {session_id_value}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] close_session failed: {e}\")\n",
    "\n",
    "    if predictor_obj is not None:\n",
    "        try:\n",
    "            predictor_obj.shutdown()\n",
    "            print(\"[cleanup] predictor shutdown finished\")\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] predictor.shutdown() failed: {e}\")\n",
    "\n",
    "    cleanup_process_group()\n",
    "\n",
    "\n",
    "def load_video_frames_for_visualization(video_path):\n",
    "    # 仅用于可视化，不参与模型推理输入。\n",
    "    if isinstance(video_path, str) and video_path.endswith(\".mp4\"):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "        return frames\n",
    "\n",
    "    if isinstance(video_path, str) and os.path.isdir(video_path):\n",
    "        frame_names = sorted(\n",
    "            glob.glob(os.path.join(video_path, \"*.jpg\"))\n",
    "            + glob.glob(os.path.join(video_path, \"*.jpeg\"))\n",
    "            + glob.glob(os.path.join(video_path, \"*.png\"))\n",
    "        )\n",
    "        if not frame_names:\n",
    "            raise ValueError(f\"视频目录为空或无可识别帧文件: {video_path}\")\n",
    "        frames = []\n",
    "        for fp in frame_names:\n",
    "            img = cv2.imread(fp)\n",
    "            if img is None:\n",
    "                raise ValueError(f\"读取帧失败: {fp}\")\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(img)\n",
    "        return frames\n",
    "\n",
    "    raise ValueError(f\"不支持的 VIDEO_PATH: {video_path}\")\n",
    "\n",
    "\n",
    "def get_frame_size(video_frames):\n",
    "    if not video_frames:\n",
    "        raise ValueError(\"video_frames 为空\")\n",
    "    frame0 = video_frames[0]\n",
    "    if isinstance(frame0, torch.Tensor):\n",
    "        frame0 = frame0.detach().cpu().numpy()\n",
    "    if frame0.ndim == 4:\n",
    "        frame0 = frame0[0]\n",
    "    h, w = frame0.shape[:2]\n",
    "    return int(w), int(h)\n",
    "\n",
    "\n",
    "def abs_to_rel_points(points_abs, img_w, img_h):\n",
    "    return [[float(x) / img_w, float(y) / img_h] for x, y in points_abs]\n",
    "\n",
    "\n",
    "def validate_prompt_entry(entry, total_frames, img_w, img_h, tag=\"prompt\"):\n",
    "    required = [\"frame_index\", \"obj_id\", \"points\", \"labels\", \"coord_type\"]\n",
    "    for k in required:\n",
    "        if k not in entry:\n",
    "            raise ValueError(f\"[{tag}] 缺少字段: {k}; entry={entry}\")\n",
    "\n",
    "    frame_index = entry[\"frame_index\"]\n",
    "    obj_id = entry[\"obj_id\"]\n",
    "    points = entry[\"points\"]\n",
    "    labels = entry[\"labels\"]\n",
    "    coord_type = entry[\"coord_type\"]\n",
    "\n",
    "    if frame_index is None or not isinstance(frame_index, int):\n",
    "        raise ValueError(f\"[{tag}] frame_index 必须为 int，当前: {frame_index}\")\n",
    "    if frame_index < 0 or frame_index >= total_frames:\n",
    "        raise ValueError(f\"[{tag}] frame_index 越界: {frame_index}, 合法范围 [0, {total_frames - 1}]\")\n",
    "\n",
    "    if obj_id is None or not isinstance(obj_id, int):\n",
    "        raise ValueError(f\"[{tag}] obj_id 不能为空且必须为 int，当前: {obj_id}\")\n",
    "\n",
    "    if coord_type not in {\"abs\", \"rel\"}:\n",
    "        raise ValueError(f\"[{tag}] coord_type 仅支持 abs/rel，当前: {coord_type}\")\n",
    "\n",
    "    if not isinstance(points, (list, tuple)) or len(points) == 0:\n",
    "        raise ValueError(f\"[{tag}] points 不能为空\")\n",
    "    if not isinstance(labels, (list, tuple)) or len(labels) == 0:\n",
    "        raise ValueError(f\"[{tag}] labels 不能为空\")\n",
    "    if len(points) != len(labels):\n",
    "        raise ValueError(f\"[{tag}] points/labels 长度不一致: {len(points)} vs {len(labels)}\")\n",
    "\n",
    "    for i, (p, lb) in enumerate(zip(points, labels)):\n",
    "        if not isinstance(p, (list, tuple)) or len(p) != 2:\n",
    "            raise ValueError(f\"[{tag}] 第{i}个点格式错误，应为 [x, y]，当前: {p}\")\n",
    "        x, y = float(p[0]), float(p[1])\n",
    "\n",
    "        if coord_type == \"abs\":\n",
    "            if not (0 <= x < img_w and 0 <= y < img_h):\n",
    "                raise ValueError(\n",
    "                    f\"[{tag}] 第{i}个 abs 点越界: ({x}, {y}), 图像尺寸=({img_w}, {img_h})\"\n",
    "                )\n",
    "        else:\n",
    "            if not (0.0 <= x <= 1.0 and 0.0 <= y <= 1.0):\n",
    "                raise ValueError(f\"[{tag}] 第{i}个 rel 点越界: ({x}, {y}), 应在 [0,1]\")\n",
    "\n",
    "        if int(lb) not in {0, 1}:\n",
    "            raise ValueError(f\"[{tag}] 第{i}个 label 非法: {lb}, 仅支持 0/1\")\n",
    "\n",
    "\n",
    "def normalize_prompt_entry(entry, img_w, img_h):\n",
    "    points = [[float(p[0]), float(p[1])] for p in entry[\"points\"]]\n",
    "    labels = [int(v) for v in entry[\"labels\"]]\n",
    "\n",
    "    if entry[\"coord_type\"] == \"abs\":\n",
    "        points_rel = abs_to_rel_points(points, img_w, img_h)\n",
    "    else:\n",
    "        points_rel = points\n",
    "\n",
    "    return dict(\n",
    "        frame_index=int(entry[\"frame_index\"]),\n",
    "        obj_id=int(entry[\"obj_id\"]),\n",
    "        points_rel=points_rel,\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "\n",
    "def validate_and_normalize_prompt_list(\n",
    "    prompt_list,\n",
    "    total_frames,\n",
    "    img_w,\n",
    "    img_h,\n",
    "    tag,\n",
    "    allow_empty=False,\n",
    "):\n",
    "    if not isinstance(prompt_list, (list, tuple)):\n",
    "        raise ValueError(f\"[{tag}] 必须为 list\")\n",
    "    if len(prompt_list) == 0 and not allow_empty:\n",
    "        raise ValueError(f\"[{tag}] 不能为空\")\n",
    "\n",
    "    normalized = []\n",
    "    for idx, entry in enumerate(prompt_list):\n",
    "        if not isinstance(entry, dict):\n",
    "            raise ValueError(f\"[{tag}] 第{idx}项必须为 dict\")\n",
    "        validate_prompt_entry(entry, total_frames, img_w, img_h, tag=f\"{tag}[{idx}]\")\n",
    "        normalized.append(normalize_prompt_entry(entry, img_w, img_h))\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def validate_obj_id_constraints(\n",
    "    arm_left_obj_id,\n",
    "    arm_right_obj_id,\n",
    "    gripper_left_obj_id,\n",
    "    gripper_right_obj_id,\n",
    "    arm_left_prompts,\n",
    "    arm_right_prompts,\n",
    "    gripper_left_prompts,\n",
    "    gripper_right_prompts,\n",
    "):\n",
    "    obj_items = [\n",
    "        (\"arm_left_obj_id\", arm_left_obj_id),\n",
    "        (\"arm_right_obj_id\", arm_right_obj_id),\n",
    "        (\"gripper_left_obj_id\", gripper_left_obj_id),\n",
    "        (\"gripper_right_obj_id\", gripper_right_obj_id),\n",
    "    ]\n",
    "\n",
    "    for name, obj_id in obj_items:\n",
    "        if obj_id is None or not isinstance(obj_id, int):\n",
    "            raise ValueError(f\"{name} 不能为空且必须为 int，当前: {obj_id}\")\n",
    "\n",
    "    all_obj_ids = [obj_id for _, obj_id in obj_items]\n",
    "    if len(set(all_obj_ids)) != 4:\n",
    "        raise ValueError(\n",
    "            \"对象 ID 冲突：arm_left_obj_id / arm_right_obj_id / \"\n",
    "            \"gripper_left_obj_id / gripper_right_obj_id 必须互不重复，当前=\"\n",
    "            f\"{all_obj_ids}\"\n",
    "        )\n",
    "\n",
    "    def _check_prompt_obj_ids(prompt_list, expected_obj_id, prompt_tag):\n",
    "        for i, p in enumerate(prompt_list):\n",
    "            if p[\"obj_id\"] != expected_obj_id:\n",
    "                raise ValueError(\n",
    "                    f\"{prompt_tag}[{i}].obj_id={p['obj_id']} 与期望 obj_id={expected_obj_id} 不一致\"\n",
    "                )\n",
    "\n",
    "    _check_prompt_obj_ids(arm_left_prompts, arm_left_obj_id, \"ARM_LEFT_INITIAL_PROMPTS\")\n",
    "    _check_prompt_obj_ids(arm_right_prompts, arm_right_obj_id, \"ARM_RIGHT_INITIAL_PROMPTS\")\n",
    "    _check_prompt_obj_ids(gripper_left_prompts, gripper_left_obj_id, \"GRIPPER_LEFT_KEYFRAME_PROMPTS\")\n",
    "    _check_prompt_obj_ids(gripper_right_prompts, gripper_right_obj_id, \"GRIPPER_RIGHT_KEYFRAME_PROMPTS\")\n",
    "\n",
    "\n",
    "def propagate_in_video(predictor_obj, session_id_value, propagation_direction=\"forward\"):\n",
    "    outputs_per_frame = {}\n",
    "    for response in predictor_obj.handle_stream_request(\n",
    "        request=dict(\n",
    "            type=\"propagate_in_video\",\n",
    "            session_id=session_id_value,\n",
    "            propagation_direction=propagation_direction,\n",
    "        )\n",
    "    ):\n",
    "        outputs_per_frame[response[\"frame_index\"]] = response[\"outputs\"]\n",
    "    return outputs_per_frame\n",
    "\n",
    "\n",
    "def propagate_bidirectional_and_merge(predictor_obj, session_id_value, stage_name=\"\"):\n",
    "    outputs_forward = propagate_in_video(\n",
    "        predictor_obj=predictor_obj,\n",
    "        session_id_value=session_id_value,\n",
    "        propagation_direction=\"forward\",\n",
    "    )\n",
    "    outputs_backward = propagate_in_video(\n",
    "        predictor_obj=predictor_obj,\n",
    "        session_id_value=session_id_value,\n",
    "        propagation_direction=\"backward\",\n",
    "    )\n",
    "\n",
    "    merged_outputs = {}\n",
    "    merged_outputs.update(outputs_forward)\n",
    "    merged_outputs.update(outputs_backward)\n",
    "\n",
    "    stage_prefix = f\"[{stage_name}] \" if stage_name else \"\"\n",
    "    print(\n",
    "        f\"{stage_prefix}propagation summary | forward_frames={len(outputs_forward)} \"\n",
    "        f\"backward_frames={len(outputs_backward)} merged_frames={len(merged_outputs)}\"\n",
    "    )\n",
    "    return merged_outputs\n",
    "\n",
    "\n",
    "def add_point_prompt(predictor_obj, session_id_value, prompt, stage_name=\"\"):\n",
    "    points_tensor = torch.tensor(prompt[\"points_rel\"], dtype=torch.float32)\n",
    "    labels_tensor = torch.tensor(prompt[\"labels\"], dtype=torch.int32)\n",
    "\n",
    "    _ = predictor_obj.handle_request(\n",
    "        request=dict(\n",
    "            type=\"add_prompt\",\n",
    "            session_id=session_id_value,\n",
    "            frame_index=prompt[\"frame_index\"],\n",
    "            points=points_tensor,\n",
    "            point_labels=labels_tensor,\n",
    "            obj_id=prompt[\"obj_id\"],\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        f\"[{stage_name}] add_prompt done | frame={prompt['frame_index']} obj_id={prompt['obj_id']} points={len(prompt['points_rel'])}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def apply_prompt_list(predictor_obj, session_id_value, prompt_list, stage_name=\"\"):\n",
    "    for p in prompt_list:\n",
    "        add_point_prompt(predictor_obj, session_id_value, p, stage_name=stage_name)\n",
    "\n",
    "\n",
    "def add_text_prompt(predictor_obj, session_id_value, frame_index, text_prompt, stage_name=\"\"):\n",
    "    if not isinstance(text_prompt, str) or len(text_prompt.strip()) == 0:\n",
    "        raise ValueError(\"text_prompt 不能为空，请设置 ARM_BOOTSTRAP_TEXT_PROMPT\")\n",
    "\n",
    "    _ = predictor_obj.handle_request(\n",
    "        request=dict(\n",
    "            type=\"add_prompt\",\n",
    "            session_id=session_id_value,\n",
    "            frame_index=int(frame_index),\n",
    "            text=text_prompt.strip(),\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        f\"[{stage_name}] add_text_prompt done | frame={int(frame_index)} text={text_prompt.strip()!r}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def resolve_stage_a_bootstrap_configs(stage_side_configs, total_frames):\n",
    "    if not isinstance(stage_side_configs, (list, tuple)) or len(stage_side_configs) == 0:\n",
    "        raise ValueError(\"stage_side_configs 必须是非空 list\")\n",
    "\n",
    "    resolved_configs = []\n",
    "\n",
    "    for idx, cfg in enumerate(stage_side_configs):\n",
    "        side_name = str(cfg.get(\"side_name\", f\"side-{idx}\"))\n",
    "        prompt_list = cfg.get(\"prompt_list\", [])\n",
    "        bootstrap_text_prompt = cfg.get(\"bootstrap_text_prompt\", \"\")\n",
    "        fallback_text_prompt = cfg.get(\"fallback_text_prompt\", \"\")\n",
    "        bootstrap_frame_index = cfg.get(\"bootstrap_frame_index\", None)\n",
    "\n",
    "        has_points = len(prompt_list) > 0\n",
    "        user_text = bootstrap_text_prompt.strip() if isinstance(bootstrap_text_prompt, str) else \"\"\n",
    "        fallback_text = fallback_text_prompt.strip() if isinstance(fallback_text_prompt, str) else \"\"\n",
    "\n",
    "        if user_text:\n",
    "            resolved_text = user_text\n",
    "            text_source = \"configured\"\n",
    "        elif has_points and fallback_text:\n",
    "            resolved_text = fallback_text\n",
    "            text_source = \"fallback\"\n",
    "            print(\n",
    "                f\"[stage A][bootstrap][{side_name}] 文本提示为空，自动使用 fallback: {resolved_text!r}\"\n",
    "            )\n",
    "        elif has_points:\n",
    "            raise ValueError(\n",
    "                f\"[{side_name}] 检测到 arm points，但 bootstrap 文本为空且无 fallback。\"\n",
    "                \"请设置对应侧的 *_BOOTSTRAP_TEXT_PROMPT 或 *_BOOTSTRAP_FALLBACK_TEXT_PROMPT。\"\n",
    "            )\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if bootstrap_frame_index is None:\n",
    "            resolved_frame = int(prompt_list[0][\"frame_index\"]) if has_points else 0\n",
    "        else:\n",
    "            if not isinstance(bootstrap_frame_index, int):\n",
    "                raise ValueError(\n",
    "                    f\"[{side_name}] bootstrap_frame_index 必须为 int 或 None，当前: {bootstrap_frame_index}\"\n",
    "                )\n",
    "            if bootstrap_frame_index < 0 or bootstrap_frame_index >= total_frames:\n",
    "                raise ValueError(\n",
    "                    f\"[{side_name}] bootstrap_frame_index 越界: {bootstrap_frame_index}, \"\n",
    "                    f\"合法范围 [0, {total_frames - 1}]\"\n",
    "                )\n",
    "            resolved_frame = int(bootstrap_frame_index)\n",
    "\n",
    "        resolved_configs.append(\n",
    "            dict(\n",
    "                side_name=side_name,\n",
    "                text_prompt=resolved_text,\n",
    "                text_source=text_source,\n",
    "                frame_index=resolved_frame,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if len(resolved_configs) == 0:\n",
    "        raise ValueError(\n",
    "            \"阶段A缺少可用提示：左右机械臂均未提供 bootstrap 文本，也没有可触发 fallback 的 points。\"\n",
    "        )\n",
    "\n",
    "    return resolved_configs\n",
    "\n",
    "\n",
    "def visualize_outputs(outputs_per_frame, video_frames, stride=60, max_plots=8, title=\"SAM3 outputs\"):\n",
    "    outputs_for_vis = prepare_masks_for_visualization(outputs_per_frame)\n",
    "    frame_indices = list(range(0, len(video_frames), stride))[:max_plots]\n",
    "\n",
    "    if not frame_indices:\n",
    "        frame_indices = [0]\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    for frame_idx in frame_indices:\n",
    "        visualize_formatted_frame_output(\n",
    "            frame_idx,\n",
    "            video_frames,\n",
    "            outputs_list=[outputs_for_vis],\n",
    "            titles=[title],\n",
    "            figsize=(6, 4),\n",
    "        )\n",
    "\n",
    "\n",
    "def resolve_export_obj_ids(export_mode, arm_obj_ids, gripper_obj_ids, custom_obj_ids=None):\n",
    "    custom_obj_ids = custom_obj_ids or []\n",
    "    arm_obj_ids = sorted(set(int(x) for x in arm_obj_ids))\n",
    "    gripper_obj_ids = sorted(set(int(x) for x in gripper_obj_ids))\n",
    "\n",
    "    if export_mode == \"arm-only\":\n",
    "        return arm_obj_ids\n",
    "    if export_mode == \"gripper-only\":\n",
    "        return gripper_obj_ids\n",
    "    if export_mode == \"union\":\n",
    "        return sorted(set(arm_obj_ids + gripper_obj_ids))\n",
    "    if export_mode == \"custom\":\n",
    "        if len(custom_obj_ids) == 0:\n",
    "            raise ValueError(\"EXPORT_MODE=custom 时，EXPORT_CUSTOM_OBJ_IDS 不能为空\")\n",
    "        return sorted(set(int(x) for x in custom_obj_ids))\n",
    "\n",
    "    raise ValueError(f\"不支持的 EXPORT_MODE: {export_mode}\")\n",
    "\n",
    "\n",
    "def save_masks_for_propainter(\n",
    "    outputs_per_frame,\n",
    "    video_frames,\n",
    "    output_dir,\n",
    "    target_obj_ids,\n",
    "    dilate_radius=8,\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    img_w, img_h = get_frame_size(video_frames)\n",
    "    num_frames = len(video_frames)\n",
    "\n",
    "    kernel = None\n",
    "    if dilate_radius > 0:\n",
    "        kernel_size = 2 * int(dilate_radius) + 1\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        print(f\"[export] dilation enabled: radius={dilate_radius}, kernel={kernel_size}x{kernel_size}\")\n",
    "\n",
    "    print(f\"[export] size={img_w}x{img_h}, frames={num_frames}, target_obj_ids={target_obj_ids}\")\n",
    "\n",
    "    saved_paths = []\n",
    "    target_set = set(target_obj_ids)\n",
    "\n",
    "    for frame_idx in range(num_frames):\n",
    "        combined_mask = np.zeros((img_h, img_w), dtype=np.uint8)\n",
    "\n",
    "        obj_dict = outputs_per_frame.get(frame_idx, {})\n",
    "        for obj_id, mask in obj_dict.items():\n",
    "            if int(obj_id) not in target_set:\n",
    "                continue\n",
    "\n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                mask = mask.detach().cpu().numpy()\n",
    "            if mask.ndim > 2:\n",
    "                mask = np.squeeze(mask)\n",
    "\n",
    "            binary = (mask > 0).astype(np.uint8) * 255\n",
    "            combined_mask = np.maximum(combined_mask, binary)\n",
    "\n",
    "        if kernel is not None and np.any(combined_mask):\n",
    "            combined_mask = cv2.dilate(combined_mask, kernel, iterations=1)\n",
    "\n",
    "        out_fp = os.path.join(output_dir, f\"{frame_idx:05d}.png\")\n",
    "        Image.fromarray(combined_mask, mode=\"L\").save(out_fp)\n",
    "        saved_paths.append(out_fp)\n",
    "\n",
    "        if frame_idx % 50 == 0:\n",
    "            print(f\"[export] frame {frame_idx:05d}/{num_frames - 1:05d} done\")\n",
    "\n",
    "    print(f\"[export] finished, saved {len(saved_paths)} masks to: {output_dir}\")\n",
    "    return saved_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065b21c",
   "metadata": {},
   "source": [
    "## 1) 载入可视化帧 + 校验配置 + 初始化 predictor/session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 反复执行时，先清理旧资源，避免 NCCL 初始化异常\n",
    "if \"predictor\" in globals() and predictor is not None:\n",
    "    print(\"[init] cleaning previous predictor/session before re-run\")\n",
    "    cleanup_resources(predictor_obj=predictor, session_id_value=session_id)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA_VISIBLE_DEVICES\n",
    "print(f\"[init] CUDA_VISIBLE_DEVICES={os.environ.get('CUDA_VISIBLE_DEVICES')}\")\n",
    "\n",
    "video_frames_for_vis = load_video_frames_for_visualization(VIDEO_PATH)\n",
    "TOTAL_FRAMES = len(video_frames_for_vis)\n",
    "IMG_WIDTH, IMG_HEIGHT = get_frame_size(video_frames_for_vis)\n",
    "print(f\"[init] loaded frames={TOTAL_FRAMES}, size={IMG_WIDTH}x{IMG_HEIGHT}\")\n",
    "\n",
    "if USE_VISUAL_ANNOTATION_EXPORT:\n",
    "    if isinstance(ANNOTATION_EXPORT_PROMPTS, dict):\n",
    "        ARM_LEFT_INITIAL_PROMPTS = ANNOTATION_EXPORT_PROMPTS.get(\n",
    "            \"ARM_LEFT_INITIAL_PROMPTS\", ARM_LEFT_INITIAL_PROMPTS\n",
    "        )\n",
    "        ARM_RIGHT_INITIAL_PROMPTS = ANNOTATION_EXPORT_PROMPTS.get(\n",
    "            \"ARM_RIGHT_INITIAL_PROMPTS\", ARM_RIGHT_INITIAL_PROMPTS\n",
    "        )\n",
    "        GRIPPER_LEFT_KEYFRAME_PROMPTS = ANNOTATION_EXPORT_PROMPTS.get(\n",
    "            \"GRIPPER_LEFT_KEYFRAME_PROMPTS\", GRIPPER_LEFT_KEYFRAME_PROMPTS\n",
    "        )\n",
    "        GRIPPER_RIGHT_KEYFRAME_PROMPTS = ANNOTATION_EXPORT_PROMPTS.get(\n",
    "            \"GRIPPER_RIGHT_KEYFRAME_PROMPTS\", GRIPPER_RIGHT_KEYFRAME_PROMPTS\n",
    "        )\n",
    "        print(\"[annotation] using prompts exported from visual annotation cells\")\n",
    "    else:\n",
    "        print(\n",
    "            \"[annotation][warn] USE_VISUAL_ANNOTATION_EXPORT=True 但 ANNOTATION_EXPORT_PROMPTS 无效，\"\n",
    "            \"继续使用手工配置的 *_PROMPTS\"\n",
    "        )\n",
    "\n",
    "arm_left_prompts_norm = validate_and_normalize_prompt_list(\n",
    "    ARM_LEFT_INITIAL_PROMPTS,\n",
    "    total_frames=TOTAL_FRAMES,\n",
    "    img_w=IMG_WIDTH,\n",
    "    img_h=IMG_HEIGHT,\n",
    "    tag=\"ARM_LEFT_INITIAL_PROMPTS\",\n",
    "    allow_empty=True,\n",
    ")\n",
    "\n",
    "arm_right_prompts_norm = validate_and_normalize_prompt_list(\n",
    "    ARM_RIGHT_INITIAL_PROMPTS,\n",
    "    total_frames=TOTAL_FRAMES,\n",
    "    img_w=IMG_WIDTH,\n",
    "    img_h=IMG_HEIGHT,\n",
    "    tag=\"ARM_RIGHT_INITIAL_PROMPTS\",\n",
    "    allow_empty=True,\n",
    ")\n",
    "\n",
    "gripper_left_prompts_norm = validate_and_normalize_prompt_list(\n",
    "    GRIPPER_LEFT_KEYFRAME_PROMPTS,\n",
    "    total_frames=TOTAL_FRAMES,\n",
    "    img_w=IMG_WIDTH,\n",
    "    img_h=IMG_HEIGHT,\n",
    "    tag=\"GRIPPER_LEFT_KEYFRAME_PROMPTS\",\n",
    "    allow_empty=True,\n",
    ")\n",
    "\n",
    "gripper_right_prompts_norm = validate_and_normalize_prompt_list(\n",
    "    GRIPPER_RIGHT_KEYFRAME_PROMPTS,\n",
    "    total_frames=TOTAL_FRAMES,\n",
    "    img_w=IMG_WIDTH,\n",
    "    img_h=IMG_HEIGHT,\n",
    "    tag=\"GRIPPER_RIGHT_KEYFRAME_PROMPTS\",\n",
    "    allow_empty=True,\n",
    ")\n",
    "\n",
    "validate_obj_id_constraints(\n",
    "    arm_left_obj_id=arm_left_obj_id,\n",
    "    arm_right_obj_id=arm_right_obj_id,\n",
    "    gripper_left_obj_id=gripper_left_obj_id,\n",
    "    gripper_right_obj_id=gripper_right_obj_id,\n",
    "    arm_left_prompts=arm_left_prompts_norm,\n",
    "    arm_right_prompts=arm_right_prompts_norm,\n",
    "    gripper_left_prompts=gripper_left_prompts_norm,\n",
    "    gripper_right_prompts=gripper_right_prompts_norm,\n",
    ")\n",
    "\n",
    "print(\"[init] prompt validation passed\")\n",
    "print(\n",
    "    f\"[init] ARM prompt count: left={len(arm_left_prompts_norm)}, right={len(arm_right_prompts_norm)} | \"\n",
    "    f\"GRIPPER prompt count: left={len(gripper_left_prompts_norm)}, right={len(gripper_right_prompts_norm)}\"\n",
    ")\n",
    "print(\n",
    "    f\"[init] configured object IDs: arms={[arm_left_obj_id, arm_right_obj_id]}, \"\n",
    "    f\"grippers={[gripper_left_obj_id, gripper_right_obj_id]}\"\n",
    ")\n",
    "\n",
    "gpus_to_use = range(torch.cuda.device_count())\n",
    "predictor = build_sam3_video_predictor(\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    gpus_to_use=gpus_to_use,\n",
    "    apply_temporal_disambiguation=APPLY_TEMPORAL_DISAMBIGUATION,\n",
    ")\n",
    "\n",
    "start_response = predictor.handle_request(\n",
    "    request=dict(\n",
    "        type=\"start_session\",\n",
    "        resource_path=VIDEO_PATH,\n",
    "    )\n",
    ")\n",
    "session_id = start_response[\"session_id\"]\n",
    "print(f\"[init] session started: {session_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85399a",
   "metadata": {},
   "source": [
    "## 1.5) 可视化点标注（解耦采集，不触发推理）\n",
    "\n",
    "最小使用说明：\n",
    "1. 先运行 `1) 初始化`（上一段 code cell，确保已加载 `video_frames_for_vis` / `TOTAL_FRAMES`）。\n",
    "2. 运行下方可视化标注 cell：\n",
    "   - `Frame` 选择标注帧；\n",
    "   - `Object` 选择对象（左臂/右臂/左夹爪/右夹爪）；\n",
    "   - `Point Label` 选择 positive(1) / negative(0)；\n",
    "   - 在图上点击添加点；\n",
    "   - `Clear Current Obj@Frame` 清空当前对象在当前帧的点。\n",
    "3. 点击 `Export Prompts` 后会生成 `ANNOTATION_EXPORT_PROMPTS`，并自动将 `USE_VISUAL_ANNOTATION_EXPORT=True`。\n",
    "4. 继续运行 Stage A / Stage B，主流程不变，仅数据来源切到导出的结构化提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化标注：在消费坐标前，先做可见点选并导出为 *_PROMPTS 兼容结构\n",
    "import json\n",
    "\n",
    "ANNOTATION_OBJECT_SPECS = {\n",
    "    \"arm_left\": {\n",
    "        \"display\": \"左臂\",\n",
    "        \"obj_id\": int(arm_left_obj_id),\n",
    "        \"target\": \"ARM_LEFT_INITIAL_PROMPTS\",\n",
    "    },\n",
    "    \"arm_right\": {\n",
    "        \"display\": \"右臂\",\n",
    "        \"obj_id\": int(arm_right_obj_id),\n",
    "        \"target\": \"ARM_RIGHT_INITIAL_PROMPTS\",\n",
    "    },\n",
    "    \"gripper_left\": {\n",
    "        \"display\": \"左夹爪\",\n",
    "        \"obj_id\": int(gripper_left_obj_id),\n",
    "        \"target\": \"GRIPPER_LEFT_KEYFRAME_PROMPTS\",\n",
    "    },\n",
    "    \"gripper_right\": {\n",
    "        \"display\": \"右夹爪\",\n",
    "        \"obj_id\": int(gripper_right_obj_id),\n",
    "        \"target\": \"GRIPPER_RIGHT_KEYFRAME_PROMPTS\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def _append_click(store, obj_key, frame_idx, x, y, label):\n",
    "    frame_idx = int(frame_idx)\n",
    "    store[obj_key].setdefault(frame_idx, []).append(\n",
    "        {\"x\": int(x), \"y\": int(y), \"label\": int(label)}\n",
    "    )\n",
    "\n",
    "\n",
    "def _seed_store_from_prompt_list(store, obj_key, prompt_list, img_w, img_h):\n",
    "    for entry in (prompt_list or []):\n",
    "        frame_idx = int(entry[\"frame_index\"])\n",
    "        coord_type = entry.get(\"coord_type\", \"abs\")\n",
    "        points = entry.get(\"points\", [])\n",
    "        labels = entry.get(\"labels\", [])\n",
    "        for p, lb in zip(points, labels):\n",
    "            if coord_type == \"rel\":\n",
    "                x = int(round(float(p[0]) * max(img_w - 1, 1)))\n",
    "                y = int(round(float(p[1]) * max(img_h - 1, 1)))\n",
    "            else:\n",
    "                x = int(round(float(p[0])))\n",
    "                y = int(round(float(p[1])))\n",
    "            x = max(0, min(int(img_w) - 1, x))\n",
    "            y = max(0, min(int(img_h) - 1, y))\n",
    "            _append_click(store, obj_key, frame_idx, x, y, int(lb))\n",
    "\n",
    "\n",
    "def _prompt_list_from_store(store, obj_key, obj_id):\n",
    "    prompt_list = []\n",
    "    for frame_idx in sorted(store[obj_key].keys()):\n",
    "        clicks = store[obj_key][frame_idx]\n",
    "        if len(clicks) == 0:\n",
    "            continue\n",
    "        prompt_list.append(\n",
    "            {\n",
    "                \"frame_index\": int(frame_idx),\n",
    "                \"obj_id\": int(obj_id),\n",
    "                \"coord_type\": \"abs\",\n",
    "                \"points\": [[int(c[\"x\"]), int(c[\"y\"])] for c in clicks],\n",
    "                \"labels\": [int(c[\"label\"]) for c in clicks],\n",
    "            }\n",
    "        )\n",
    "    return prompt_list\n",
    "\n",
    "\n",
    "def export_annotation_prompts(annotation_store):\n",
    "    return {\n",
    "        \"ARM_LEFT_INITIAL_PROMPTS\": _prompt_list_from_store(\n",
    "            annotation_store, \"arm_left\", ANNOTATION_OBJECT_SPECS[\"arm_left\"][\"obj_id\"]\n",
    "        ),\n",
    "        \"ARM_RIGHT_INITIAL_PROMPTS\": _prompt_list_from_store(\n",
    "            annotation_store, \"arm_right\", ANNOTATION_OBJECT_SPECS[\"arm_right\"][\"obj_id\"]\n",
    "        ),\n",
    "        \"GRIPPER_LEFT_KEYFRAME_PROMPTS\": _prompt_list_from_store(\n",
    "            annotation_store,\n",
    "            \"gripper_left\",\n",
    "            ANNOTATION_OBJECT_SPECS[\"gripper_left\"][\"obj_id\"],\n",
    "        ),\n",
    "        \"GRIPPER_RIGHT_KEYFRAME_PROMPTS\": _prompt_list_from_store(\n",
    "            annotation_store,\n",
    "            \"gripper_right\",\n",
    "            ANNOTATION_OBJECT_SPECS[\"gripper_right\"][\"obj_id\"],\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "ANNOTATION_MANUAL_TEMPLATE = {\n",
    "    \"ARM_LEFT_INITIAL_PROMPTS\": ARM_LEFT_INITIAL_PROMPTS,\n",
    "    \"ARM_RIGHT_INITIAL_PROMPTS\": ARM_RIGHT_INITIAL_PROMPTS,\n",
    "    \"GRIPPER_LEFT_KEYFRAME_PROMPTS\": GRIPPER_LEFT_KEYFRAME_PROMPTS,\n",
    "    \"GRIPPER_RIGHT_KEYFRAME_PROMPTS\": GRIPPER_RIGHT_KEYFRAME_PROMPTS,\n",
    "}\n",
    "\n",
    "annotation_store = {k: {} for k in ANNOTATION_OBJECT_SPECS.keys()}\n",
    "\n",
    "# 预填充：把当前手工配置加载到可视化标注器里（便于增量编辑）\n",
    "_seed_store_from_prompt_list(annotation_store, \"arm_left\", ARM_LEFT_INITIAL_PROMPTS, IMG_WIDTH, IMG_HEIGHT)\n",
    "_seed_store_from_prompt_list(annotation_store, \"arm_right\", ARM_RIGHT_INITIAL_PROMPTS, IMG_WIDTH, IMG_HEIGHT)\n",
    "_seed_store_from_prompt_list(\n",
    "    annotation_store,\n",
    "    \"gripper_left\",\n",
    "    GRIPPER_LEFT_KEYFRAME_PROMPTS,\n",
    "    IMG_WIDTH,\n",
    "    IMG_HEIGHT,\n",
    ")\n",
    "_seed_store_from_prompt_list(\n",
    "    annotation_store,\n",
    "    \"gripper_right\",\n",
    "    GRIPPER_RIGHT_KEYFRAME_PROMPTS,\n",
    "    IMG_WIDTH,\n",
    "    IMG_HEIGHT,\n",
    ")\n",
    "\n",
    "# 默认导出内容先等于当前配置（fallback / 未点击导出时可手工赋值）\n",
    "if not isinstance(ANNOTATION_EXPORT_PROMPTS, dict):\n",
    "    ANNOTATION_EXPORT_PROMPTS = dict(ANNOTATION_MANUAL_TEMPLATE)\n",
    "\n",
    "widget_ready = False\n",
    "widget_error = None\n",
    "\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ip = get_ipython()\n",
    "    if ip is None:\n",
    "        raise RuntimeError(\"当前不在 IPython/Jupyter 环境\")\n",
    "\n",
    "    # 尽量对齐参考 notebook 的交互体验\n",
    "    ip.run_line_magic(\"matplotlib\", \"widget\")\n",
    "\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "\n",
    "    widget_ready = True\n",
    "except Exception as e:\n",
    "    widget_error = e\n",
    "    widget_ready = False\n",
    "\n",
    "if video_frames_for_vis is None or TOTAL_FRAMES is None:\n",
    "    print(\"[annotation][warn] 未检测到可视化帧，请先运行上一个初始化 cell 再执行本 cell。\")\n",
    "elif not widget_ready:\n",
    "    print(\n",
    "        \"[annotation][fallback] ipympl/ipywidgets 不可用，已回退到手工结构输入，不中断 notebook。\"\n",
    "    )\n",
    "    print(f\"[annotation][fallback] 触发原因: {widget_error}\")\n",
    "    print(\"[annotation][fallback] 请直接编辑 ANNOTATION_MANUAL_TEMPLATE 或四个 *_PROMPTS 变量。\")\n",
    "    print(\"[annotation][fallback] 然后设置 USE_VISUAL_ANNOTATION_EXPORT=True 并赋值：\")\n",
    "    print(\"    ANNOTATION_EXPORT_PROMPTS = ANNOTATION_MANUAL_TEMPLATE\")\n",
    "else:\n",
    "    frame_slider = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=max(0, int(TOTAL_FRAMES) - 1),\n",
    "        step=1,\n",
    "        description=\"Frame\",\n",
    "        continuous_update=False,\n",
    "        layout=widgets.Layout(width=\"380px\"),\n",
    "    )\n",
    "\n",
    "    object_dropdown = widgets.Dropdown(\n",
    "        options=[\n",
    "            (\n",
    "                f\"{spec['display']} (obj_id={spec['obj_id']})\",\n",
    "                key,\n",
    "            )\n",
    "            for key, spec in ANNOTATION_OBJECT_SPECS.items()\n",
    "        ],\n",
    "        value=\"arm_left\",\n",
    "        description=\"Object\",\n",
    "        layout=widgets.Layout(width=\"380px\"),\n",
    "    )\n",
    "\n",
    "    label_toggle = widgets.ToggleButtons(\n",
    "        options=[(\"positive(1)\", 1), (\"negative(0)\", 0)],\n",
    "        value=1,\n",
    "        description=\"Point Label\",\n",
    "        layout=widgets.Layout(width=\"380px\"),\n",
    "    )\n",
    "\n",
    "    clear_btn = widgets.Button(\n",
    "        description=\"Clear Current Obj@Frame\",\n",
    "        button_style=\"warning\",\n",
    "        layout=widgets.Layout(width=\"220px\"),\n",
    "    )\n",
    "    refresh_btn = widgets.Button(\n",
    "        description=\"Refresh\",\n",
    "        button_style=\"\",\n",
    "        layout=widgets.Layout(width=\"100px\"),\n",
    "    )\n",
    "    export_btn = widgets.Button(\n",
    "        description=\"Export Prompts\",\n",
    "        button_style=\"success\",\n",
    "        layout=widgets.Layout(width=\"140px\"),\n",
    "    )\n",
    "\n",
    "    status_out = widgets.Output(layout=widgets.Layout(border=\"1px solid #aaa\"))\n",
    "    export_out = widgets.Output(layout=widgets.Layout(border=\"1px solid #aaa\"))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    ann_fig, ann_ax = plt.subplots(1, 1, figsize=(9, 6))\n",
    "    ann_fig.canvas.toolbar_visible = True\n",
    "\n",
    "    def _current_ctx():\n",
    "        return int(frame_slider.value), str(object_dropdown.value), int(label_toggle.value)\n",
    "\n",
    "    def _draw_annotation_canvas():\n",
    "        frame_idx, obj_key, _ = _current_ctx()\n",
    "        frame = video_frames_for_vis[frame_idx]\n",
    "\n",
    "        ann_ax.clear()\n",
    "        ann_ax.imshow(frame)\n",
    "        ann_ax.set_title(\n",
    "            f\"Frame={frame_idx} | Object={ANNOTATION_OBJECT_SPECS[obj_key]['display']} \"\n",
    "            f\"(obj_id={ANNOTATION_OBJECT_SPECS[obj_key]['obj_id']}) | \"\n",
    "            f\"CurrentLabel={label_toggle.value}\"\n",
    "        )\n",
    "        ann_ax.set_axis_off()\n",
    "\n",
    "        clicks = annotation_store[obj_key].get(frame_idx, [])\n",
    "        for idx, c in enumerate(clicks):\n",
    "            x, y, lb = int(c[\"x\"]), int(c[\"y\"]), int(c[\"label\"])\n",
    "            color = \"lime\" if lb == 1 else \"red\"\n",
    "            marker = \"o\" if lb == 1 else \"x\"\n",
    "            ann_ax.plot(x, y, marker=marker, color=color, markersize=8, markeredgewidth=2)\n",
    "            ann_ax.text(\n",
    "                x + 6,\n",
    "                y,\n",
    "                f\"{idx}:{lb}\",\n",
    "                color=\"white\",\n",
    "                fontsize=9,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"black\", alpha=0.5),\n",
    "            )\n",
    "\n",
    "        with status_out:\n",
    "            status_out.clear_output()\n",
    "            print(\n",
    "                f\"[annotation] 当前对象={ANNOTATION_OBJECT_SPECS[obj_key]['display']} \"\n",
    "                f\"frame={frame_idx} 点数={len(clicks)}\"\n",
    "            )\n",
    "            print(\"[annotation] 点击图像可添加点；绿色=o=positive(1)，红色=x=negative(0)\")\n",
    "\n",
    "        ann_fig.canvas.draw_idle()\n",
    "\n",
    "    def _on_canvas_click(event):\n",
    "        if event.inaxes != ann_ax or event.xdata is None or event.ydata is None:\n",
    "            return\n",
    "\n",
    "        frame_idx, obj_key, point_label = _current_ctx()\n",
    "        x = int(round(float(event.xdata)))\n",
    "        y = int(round(float(event.ydata)))\n",
    "        x = max(0, min(int(IMG_WIDTH) - 1, x))\n",
    "        y = max(0, min(int(IMG_HEIGHT) - 1, y))\n",
    "\n",
    "        _append_click(annotation_store, obj_key, frame_idx, x, y, point_label)\n",
    "        _draw_annotation_canvas()\n",
    "\n",
    "    def _on_clear_clicked(_):\n",
    "        frame_idx, obj_key, _ = _current_ctx()\n",
    "        if frame_idx in annotation_store[obj_key]:\n",
    "            annotation_store[obj_key].pop(frame_idx, None)\n",
    "        _draw_annotation_canvas()\n",
    "\n",
    "    def _on_refresh_clicked(_):\n",
    "        _draw_annotation_canvas()\n",
    "\n",
    "    def _on_export_clicked(_):\n",
    "        global ANNOTATION_EXPORT_PROMPTS, USE_VISUAL_ANNOTATION_EXPORT\n",
    "\n",
    "        ANNOTATION_EXPORT_PROMPTS = export_annotation_prompts(annotation_store)\n",
    "        USE_VISUAL_ANNOTATION_EXPORT = True\n",
    "\n",
    "        with export_out:\n",
    "            export_out.clear_output()\n",
    "            summary = {\n",
    "                k: len(v)\n",
    "                for k, v in ANNOTATION_EXPORT_PROMPTS.items()\n",
    "            }\n",
    "            print(\"[annotation] 导出完成，已自动设置 USE_VISUAL_ANNOTATION_EXPORT=True\")\n",
    "            print(f\"[annotation] 各对象关键帧条目数: {summary}\")\n",
    "            print(\"[annotation] 导出结构（可直接被 Stage A/B 消费）:\")\n",
    "            print(json.dumps(ANNOTATION_EXPORT_PROMPTS, ensure_ascii=False, indent=2))\n",
    "\n",
    "    frame_slider.observe(lambda _: _draw_annotation_canvas(), names=\"value\")\n",
    "    object_dropdown.observe(lambda _: _draw_annotation_canvas(), names=\"value\")\n",
    "    label_toggle.observe(lambda _: _draw_annotation_canvas(), names=\"value\")\n",
    "    clear_btn.on_click(_on_clear_clicked)\n",
    "    refresh_btn.on_click(_on_refresh_clicked)\n",
    "    export_btn.on_click(_on_export_clicked)\n",
    "    ann_fig.canvas.mpl_connect(\"button_press_event\", _on_canvas_click)\n",
    "\n",
    "    controls = widgets.VBox(\n",
    "        [\n",
    "            widgets.HBox([frame_slider, object_dropdown]),\n",
    "            widgets.HBox([label_toggle]),\n",
    "            widgets.HBox([clear_btn, refresh_btn, export_btn]),\n",
    "            status_out,\n",
    "            export_out,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    display(controls)\n",
    "    _draw_annotation_canvas()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679df62",
   "metadata": {},
   "source": [
    "## 2) 阶段 A：先 bootstrap 普通传播，再做机械臂 points refinement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_a_bootstrap_configs = resolve_stage_a_bootstrap_configs(\n",
    "    stage_side_configs=[\n",
    "        dict(\n",
    "            side_name=\"left\",\n",
    "            bootstrap_text_prompt=ARM_LEFT_BOOTSTRAP_TEXT_PROMPT,\n",
    "            fallback_text_prompt=ARM_LEFT_BOOTSTRAP_FALLBACK_TEXT_PROMPT,\n",
    "            bootstrap_frame_index=ARM_LEFT_BOOTSTRAP_FRAME_INDEX,\n",
    "            prompt_list=arm_left_prompts_norm,\n",
    "        ),\n",
    "        dict(\n",
    "            side_name=\"right\",\n",
    "            bootstrap_text_prompt=ARM_RIGHT_BOOTSTRAP_TEXT_PROMPT,\n",
    "            fallback_text_prompt=ARM_RIGHT_BOOTSTRAP_FALLBACK_TEXT_PROMPT,\n",
    "            bootstrap_frame_index=ARM_RIGHT_BOOTSTRAP_FRAME_INDEX,\n",
    "            prompt_list=arm_right_prompts_norm,\n",
    "        ),\n",
    "    ],\n",
    "    total_frames=TOTAL_FRAMES,\n",
    ")\n",
    "\n",
    "stage_a_active_obj_ids = sorted({arm_left_obj_id, arm_right_obj_id})\n",
    "print(f\"[stage A] active_obj_ids={stage_a_active_obj_ids}\")\n",
    "\n",
    "for cfg in stage_a_bootstrap_configs:\n",
    "    print(\n",
    "        f\"[stage A][bootstrap] side={cfg['side_name']} frame={cfg['frame_index']} \"\n",
    "        f\"text_source={cfg['text_source']}\"\n",
    "    )\n",
    "    add_text_prompt(\n",
    "        predictor_obj=predictor,\n",
    "        session_id_value=session_id,\n",
    "        frame_index=cfg[\"frame_index\"],\n",
    "        text_prompt=cfg[\"text_prompt\"],\n",
    "        stage_name=f\"stage A/bootstrap/{cfg['side_name']}\",\n",
    "    )\n",
    "\n",
    "print(\"[stage A][bootstrap] propagating bidirectional (forward + backward) ...\")\n",
    "outputs_stage_a = propagate_bidirectional_and_merge(\n",
    "    predictor_obj=predictor,\n",
    "    session_id_value=session_id,\n",
    "    stage_name=\"stage A/bootstrap\",\n",
    ")\n",
    "print(f\"[stage A][bootstrap] done, merged frame outputs={len(outputs_stage_a)}\")\n",
    "\n",
    "arm_prompts_merged = sorted(\n",
    "    list(arm_left_prompts_norm) + list(arm_right_prompts_norm),\n",
    "    key=lambda x: (x[\"frame_index\"], x[\"obj_id\"]),\n",
    ")\n",
    "\n",
    "if len(arm_prompts_merged) > 0:\n",
    "    print(\"[stage A][refinement] applying left/right arm point prompts after bootstrap ...\")\n",
    "    apply_prompt_list(\n",
    "        predictor_obj=predictor,\n",
    "        session_id_value=session_id,\n",
    "        prompt_list=arm_prompts_merged,\n",
    "        stage_name=\"stage A/refinement\",\n",
    "    )\n",
    "\n",
    "    print(\"[stage A][refinement] propagating bidirectional (forward + backward) ...\")\n",
    "    outputs_stage_a = propagate_bidirectional_and_merge(\n",
    "        predictor_obj=predictor,\n",
    "        session_id_value=session_id,\n",
    "        stage_name=\"stage A/refinement\",\n",
    "    )\n",
    "    print(f\"[stage A][refinement] done, merged frame outputs={len(outputs_stage_a)}\")\n",
    "else:\n",
    "    print(\"[stage A][refinement] no arm point prompts configured; keeping bootstrap outputs as stage A result\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d455e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_outputs(\n",
    "    outputs_per_frame=outputs_stage_a,\n",
    "    video_frames=video_frames_for_vis,\n",
    "    stride=VIS_FRAME_STRIDE,\n",
    "    max_plots=VIS_MAX_PLOTS,\n",
    "    title=\"Stage A: Arm segmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc3dc34",
   "metadata": {},
   "source": [
    "## 3) 阶段 B：关键帧 points 新增 gripper（全新 obj_id）并再次传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec78c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_b_new_obj_ids = sorted({gripper_left_obj_id, gripper_right_obj_id})\n",
    "stage_b_union_obj_ids = sorted({\n",
    "    arm_left_obj_id,\n",
    "    arm_right_obj_id,\n",
    "    gripper_left_obj_id,\n",
    "    gripper_right_obj_id,\n",
    "})\n",
    "print(f\"[stage B] active_obj_ids(new grippers)={stage_b_new_obj_ids}\")\n",
    "print(f\"[stage B] expected_obj_ids_after_merge={stage_b_union_obj_ids}\")\n",
    "\n",
    "gripper_prompts_merged = sorted(\n",
    "    list(gripper_left_prompts_norm) + list(gripper_right_prompts_norm),\n",
    "    key=lambda x: (x[\"frame_index\"], x[\"obj_id\"]),\n",
    ")\n",
    "\n",
    "if len(gripper_prompts_merged) > 0:\n",
    "    print(\"[stage B] injecting left/right gripper prompts...\")\n",
    "    apply_prompt_list(\n",
    "        predictor_obj=predictor,\n",
    "        session_id_value=session_id,\n",
    "        prompt_list=gripper_prompts_merged,\n",
    "        stage_name=\"stage B\",\n",
    "    )\n",
    "else:\n",
    "    print(\"[stage B] no gripper prompts configured; skipping prompt injection\")\n",
    "\n",
    "print(\"[stage B] propagating bidirectional (forward + backward) ...\")\n",
    "outputs_stage_b = propagate_bidirectional_and_merge(\n",
    "    predictor_obj=predictor,\n",
    "    session_id_value=session_id,\n",
    "    stage_name=\"stage B\",\n",
    ")\n",
    "print(f\"[stage B] done, merged frame outputs={len(outputs_stage_b)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b50c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_outputs(\n",
    "    outputs_per_frame=outputs_stage_b,\n",
    "    video_frames=video_frames_for_vis,\n",
    "    stride=VIS_FRAME_STRIDE,\n",
    "    max_plots=VIS_MAX_PLOTS,\n",
    "    title=\"Stage B: Arm + Gripper segmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326bf95",
   "metadata": {},
   "source": [
    "## 4) 导出 mask（支持 arm-only / gripper-only / union / custom）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9060028",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_obj_ids = resolve_export_obj_ids(\n",
    "    export_mode=EXPORT_MODE,\n",
    "    arm_obj_ids=[arm_left_obj_id, arm_right_obj_id],\n",
    "    gripper_obj_ids=[gripper_left_obj_id, gripper_right_obj_id],\n",
    "    custom_obj_ids=EXPORT_CUSTOM_OBJ_IDS,\n",
    ")\n",
    "\n",
    "print(f\"[export] EXPORT_MODE={EXPORT_MODE}, resolved_obj_ids={export_obj_ids}\")\n",
    "\n",
    "mask_paths = save_masks_for_propainter(\n",
    "    outputs_per_frame=outputs_stage_b,\n",
    "    video_frames=video_frames_for_vis,\n",
    "    output_dir=EXPORT_OUTPUT_DIR,\n",
    "    target_obj_ids=export_obj_ids,\n",
    "    dilate_radius=EXPORT_DILATE_RADIUS,\n",
    ")\n",
    "\n",
    "print(f\"[export] sample: first={mask_paths[0] if mask_paths else 'N/A'}\")\n",
    "print(f\"[export] sample: last={mask_paths[-1] if mask_paths else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 资源清理（session close + predictor shutdown + 进程组清理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_resources(\n",
    "    predictor_obj=predictor,\n",
    "    session_id_value=session_id,\n",
    ")\n",
    "\n",
    "predictor = None\n",
    "session_id = None\n",
    "print(\"[cleanup] globals reset done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
