{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nb1-header",
   "metadata": {},
   "source": [
    "# SAM3 Arm 分割（Session 1）\n",
    "\n",
    "**运行顺序**：`mask_config.yaml` → imports → config → init → [Arm 标注 UI] → Session 1 Arm 分割 → cleanup\n",
    "\n",
    "- text bootstrap 初始化，可选点标注精化\n",
    "- 分割结果保存到 checkpoint（`_ckpt_arm` 目录）\n",
    "- 与 `mask_2_gripper.ipynb` 完全独立，可任意顺序运行\n",
    "- 运行完成后在 `mask_3_merge.ipynb` 中合并\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b60f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_NAME = \"scene_0018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb1-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from PIL import Image\n",
    "\n",
    "import sam3\n",
    "from sam3.model_builder import build_sam3_video_predictor\n",
    "\n",
    "from mask_pipeline_tools import (\n",
    "    add_text_prompt,\n",
    "    apply_prompt_list,\n",
    "    cleanup_process_group,\n",
    "    cleanup_resources,\n",
    "    get_frame_size,\n",
    "    iter_object_masks_from_frame_output,\n",
    "    load_video_frames_for_visualization,\n",
    "    propagate_bidirectional_and_merge,\n",
    "    validate_and_normalize_prompt_list,\n",
    "    visualize_outputs,\n",
    ")\n",
    "from annotation_ui_tools import (\n",
    "    create_annotation_store,\n",
    "    create_annotation_ui,\n",
    "    load_annotation_prompts_json,\n",
    "    seed_store_from_prompt_map,\n",
    ")\n",
    "\n",
    "plt.rcParams[\"axes.titlesize\"] = 12\n",
    "plt.rcParams[\"figure.titlesize\"] = 12\n",
    "\n",
    "# 配置加载\n",
    "\n",
    "# ============================================================\n",
    "# 配置加载 — 修改 mask_config.yaml 来调整参数\n",
    "# ============================================================\n",
    "import yaml\n",
    "\n",
    "_CONFIG_PATH = Path(\"mask_config.yaml\")\n",
    "with open(_CONFIG_PATH, \"r\") as _f:\n",
    "    _cfg = yaml.safe_load(_f)\n",
    "\n",
    "TASK_NAME = _cfg['task_name']\n",
    "# SCENE_NAME = _cfg['scene_name']\n",
    "CHECKPOINT_PATH = _cfg['sam3_checkpoint']\n",
    "CUDA_VISIBLE_DEVICES = _cfg['cuda_visible_devices_arm']\n",
    "APPLY_TEMPORAL_DISAMBIGUATION = bool(_cfg['apply_temporal_disambiguation'])\n",
    "ARM_OBJ_ID = int(_cfg['arm_obj_id'])\n",
    "ARM_OBJ_ID_2 = int(_cfg['arm_obj_id_2']) if _cfg.get('arm_obj_id_2') is not None else None\n",
    "GRIPPER_LEFT_OBJ_ID = int(_cfg['gripper_left_obj_id'])\n",
    "GRIPPER_RIGHT_OBJ_ID = int(_cfg['gripper_right_obj_id'])\n",
    "ARM_TEXT_PROMPT = _cfg['arm_text_prompt']\n",
    "ARM_TEXT_BOOTSTRAP_FRAME_INDEX = int(_cfg['arm_text_bootstrap_frame_index'])\n",
    "VIS_FRAME_STRIDE = int(_cfg['vis_frame_stride'])\n",
    "VIS_MAX_PLOTS = int(_cfg['vis_max_plots'])\n",
    "EXPORT_ARM_DILATE_RADIUS = int(_cfg['export_arm_dilate_radius'])\n",
    "EXPORT_GRIPPER_DILATE_RADIUS = int(_cfg['export_gripper_dilate_radius'])\n",
    "EXPORT_LOG_EVERY = int(_cfg['export_log_every'])\n",
    "\n",
    "# Derived paths\n",
    "_data_base = _cfg['data_base_dir']\n",
    "_export_base_str = _cfg['export_base_dir']\n",
    "VIDEO_PATH = f\"{_data_base}/{TASK_NAME}/train/{SCENE_NAME}/cam_105422061350/color\"\n",
    "ANNOTATION_JSON_PATH = str(Path(VIDEO_PATH).parent / \"annotation_prompts_gripper_points.json\")\n",
    "ARM_ANNOTATION_JSON_PATH = str(Path(VIDEO_PATH).parent / \"annotation_prompts_arm_points.json\")\n",
    "EXPORT_OUTPUT_DIR = f\"{_export_base_str}/{TASK_NAME}/{SCENE_NAME}\"\n",
    "_export_base = Path(EXPORT_OUTPUT_DIR)\n",
    "CHECKPOINT_ARM_DIR     = str(_export_base.parent / (_export_base.name + \"_ckpt_arm\"))\n",
    "CHECKPOINT_GRIPPER_DIR = str(_export_base.parent / (_export_base.name + \"_ckpt_gripper\"))\n",
    "\n",
    "print(f\"[config] task={TASK_NAME}  scene={SCENE_NAME}\")\n",
    "print(f\"[config] VIDEO_PATH={VIDEO_PATH}\")\n",
    "print(f\"[config] ANNOTATION_JSON_PATH={ANNOTATION_JSON_PATH}\")\n",
    "print(f\"[config] ARM_ANNOTATION_JSON_PATH={ARM_ANNOTATION_JSON_PATH}\")\n",
    "print(f\"[config] CHECKPOINT_ARM_DIR={CHECKPOINT_ARM_DIR}\")\n",
    "print(f\"[config] CHECKPOINT_GRIPPER_DIR={CHECKPOINT_GRIPPER_DIR}\")\n",
    "print(f\"[config] EXPORT_OUTPUT_DIR={EXPORT_OUTPUT_DIR}\")\n",
    "\n",
    "# 初始化\n",
    "\n",
    "# ============================================================\n",
    "# 运行时状态（不需要修改）\n",
    "# ============================================================\n",
    "video_frames_for_vis = None\n",
    "TOTAL_FRAMES = None\n",
    "IMG_WIDTH = None\n",
    "IMG_HEIGHT = None\n",
    "\n",
    "predictor_arm = None\n",
    "session_id_arm = None\n",
    "outputs_arm = None\n",
    "\n",
    "arm_prompts_norm = None          # arm 点标注（加载后存于此）\n",
    "\n",
    "# ============================================================\n",
    "# 加载视频帧\n",
    "# ============================================================\n",
    "\n",
    "# 重复执行时先清理残留 predictor，防止 NCCL 初始化异常\n",
    "if predictor_arm is not None:\n",
    "    print('[init] cleaning up previous arm predictor')\n",
    "    cleanup_resources(predictor_obj=predictor_arm, session_id_value=session_id_arm)\n",
    "    predictor_arm = None\n",
    "    session_id_arm = None\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = CUDA_VISIBLE_DEVICES\n",
    "print(f'[init] CUDA_VISIBLE_DEVICES={os.environ.get(\"CUDA_VISIBLE_DEVICES\")}')\n",
    "\n",
    "video_frames_for_vis = load_video_frames_for_visualization(VIDEO_PATH)\n",
    "TOTAL_FRAMES = len(video_frames_for_vis)\n",
    "IMG_WIDTH, IMG_HEIGHT = get_frame_size(video_frames_for_vis)\n",
    "\n",
    "print(f'[init] frames={TOTAL_FRAMES}  size={IMG_WIDTH}x{IMG_HEIGHT}')\n",
    "print(f'[init] VIDEO_PATH={VIDEO_PATH}')\n",
    "print(f'[init] ARM_ANNOTATION_JSON_PATH={ARM_ANNOTATION_JSON_PATH}')\n",
    "print(f'[init] CHECKPOINT_ARM_DIR={CHECKPOINT_ARM_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb1-arm-anno-ui",
   "metadata": {},
   "outputs": [],
   "source": "# Arm 标注 UI\n# ============================================================\n# Arm 标注 UI\n# ============================================================\n# 标注模式\n# \"overwrite\" : 覆盖保存，UI 空白启动（默认行为）\n# \"append\"    : 追加模式，自动加载已有 JSON 到 UI，可在已有帧添加点或新增帧\n# ============================================================\nANNOTATION_MODE = \"append\"  # ← 按需切换为 \"overwrite\"\n\n# 为 arm_cable（主臂/右臂, obj_id=ARM_OBJ_ID）和\n#    arm_cable_2（左臂, obj_id=ARM_OBJ_ID_2）标注关键帧点\n# 标注完成后点击 Export 保存到 ARM_ANNOTATION_JSON_PATH\n# 若已有有效 JSON，可跳过此 cell，直接运行下方的 JSON 加载 cell\n# ============================================================\n\nARM_ANNOTATION_OBJECT_SPECS = {\n    \"arm_cable\": {\n        \"display\": \"Arm + Cable (主臂/右)\",\n        \"obj_id\": int(ARM_OBJ_ID),\n        \"target\": \"ARM_CABLE_INITIAL_PROMPTS\",\n    },\n}\nif ARM_OBJ_ID_2 is not None:\n    ARM_ANNOTATION_OBJECT_SPECS[\"arm_cable_2\"] = {\n        \"display\": \"Arm 2 (左臂)\",\n        \"obj_id\": int(ARM_OBJ_ID_2),\n        \"target\": \"ARM_CABLE_2_INITIAL_PROMPTS\",\n    }\n\n# 若 JSON 已存在，用它 seed UI\n_arm_seed_prompt_map = {\n    \"ARM_CABLE_INITIAL_PROMPTS\": [],\n    \"ARM_CABLE_2_INITIAL_PROMPTS\": [],\n    \"GRIPPER_LEFT_KEYFRAME_PROMPTS\": [],\n    \"GRIPPER_RIGHT_KEYFRAME_PROMPTS\": [],\n}\nif Path(ARM_ANNOTATION_JSON_PATH).exists():\n    try:\n        _arm_existing = load_annotation_prompts_json(\n            json_path=ARM_ANNOTATION_JSON_PATH, status_prefix=\"[arm-annotation/seed]\"\n        )\n        _arm_seed_prompt_map.update(_arm_existing)\n        print(f\"[arm-annotation] seeding UI from existing JSON: {ARM_ANNOTATION_JSON_PATH}\")\n    except Exception as _e:\n        print(f\"[arm-annotation][warn] could not seed from JSON: {_e}\")\n\n_arm_annotation_store = create_annotation_store(ARM_ANNOTATION_OBJECT_SPECS)\nseed_store_from_prompt_map(\n    store=_arm_annotation_store,\n    object_specs=ARM_ANNOTATION_OBJECT_SPECS,\n    prompt_map=_arm_seed_prompt_map,\n    img_w=IMG_WIDTH,\n    img_h=IMG_HEIGHT,\n)\n\n# Export 回调：补齐 schema 要求的全部键后保存\n# save_json_on_export=False 原因同 gripper UI：内部保存会在补齐 ARM 字段前调用\n# validate_export_prompt_map 导致 KeyError\n_arm_export_result = {}\n\ndef _on_arm_export(export_prompts):\n    global _arm_export_result\n    _arm_export_result = {\n        \"ARM_CABLE_INITIAL_PROMPTS\": export_prompts.get(\"ARM_CABLE_INITIAL_PROMPTS\", []),\n        \"ARM_CABLE_2_INITIAL_PROMPTS\": export_prompts.get(\"ARM_CABLE_2_INITIAL_PROMPTS\", []),\n        \"GRIPPER_LEFT_KEYFRAME_PROMPTS\": [],   # schema 要求，留空\n        \"GRIPPER_RIGHT_KEYFRAME_PROMPTS\": [],  # schema 要求，留空\n    }\n    from annotation_ui_tools import save_annotation_prompts_json as _save_json\n    _save_json(\n        export_prompts=_arm_export_result,\n        json_path=ARM_ANNOTATION_JSON_PATH,\n        status_prefix=\"[arm-annotation]\",\n    )\n    print(f\"[arm-annotation] saved to {ARM_ANNOTATION_JSON_PATH}\")\n\n_arm_annotation_ui = create_annotation_ui(\n    video_frames_for_vis=video_frames_for_vis,\n    total_frames=TOTAL_FRAMES,\n    img_width=IMG_WIDTH,\n    img_height=IMG_HEIGHT,\n    object_specs=ARM_ANNOTATION_OBJECT_SPECS,\n    annotation_store=_arm_annotation_store,\n    on_export=_on_arm_export,\n    auto_display=True,\n    status_prefix=\"[arm-annotation]\",\n    export_json_path=ARM_ANNOTATION_JSON_PATH,\n    save_json_on_export=False,\n)\n\n\n# ── append 模式：UI 初始化后重新加载已有标注，使其可见并可追加 ──────────────\n# create_annotation_ui 内部会清空 annotation_store；\n# 在此重新 seed，使已有点位显示在画布上，用户可直接在其基础上追加。\n# 导出时 UI 输出 旧点 + 新点，export 回调原样保存即可（无需额外合并）。\nif ANNOTATION_MODE == \"append\" and Path(ARM_ANNOTATION_JSON_PATH).exists():\n    try:\n        _arm_append_data = load_annotation_prompts_json(\n            json_path=ARM_ANNOTATION_JSON_PATH, status_prefix=\"[arm-annotation/append]\"\n        )\n        seed_store_from_prompt_map(\n            store=_arm_annotation_store,\n            object_specs=ARM_ANNOTATION_OBJECT_SPECS,\n            prompt_map=_arm_append_data,\n            img_w=IMG_WIDTH,\n            img_h=IMG_HEIGHT,\n        )\n        if _arm_annotation_ui.get(\"draw\"):\n            _arm_annotation_ui[\"draw\"](force_draw=True, full_reset=True)\n        _n_arm_frames = sum(len(v) for v in _arm_annotation_store.values())\n        print(f\"[arm-annotation/append] 已有标注已加载到 UI（{_n_arm_frames} 个对象-帧），可继续追加新点\")\n    except Exception as _e:\n        print(f\"[arm-annotation/append][warn] 加载已有标注失败，UI 以空白启动: {_e}\")\n\nif not _arm_annotation_ui.get(\"widget_ready\", False):\n    print(f\"[arm-annotation][fallback] Widget not available: {_arm_annotation_ui.get('widget_error')}\")\n    print(f\"[arm-annotation][fallback] 请直接编辑 JSON 文件: {ARM_ANNOTATION_JSON_PATH}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb1-session1-arm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session 1 — Arm 分割\n",
    "\n",
    "# ============================================================\n",
    "# 从 JSON 加载并校验 Arm 点标注（可选）\n",
    "# 若 ARM_ANNOTATION_JSON_PATH 不存在，arm_prompts_norm = []，Session 1 仅用 text bootstrap\n",
    "# ============================================================\n",
    "\n",
    "arm_prompts_norm = []\n",
    "\n",
    "if not Path(ARM_ANNOTATION_JSON_PATH).exists():\n",
    "    print(f\"[session1/arm] ARM_ANNOTATION_JSON_PATH not found, skipping arm point prompts.\")\n",
    "    print(f\"[session1/arm] path: {ARM_ANNOTATION_JSON_PATH}\")\n",
    "else:\n",
    "    try:\n",
    "        _arm_json = load_annotation_prompts_json(\n",
    "            json_path=ARM_ANNOTATION_JSON_PATH, status_prefix=\"[session1/arm]\"\n",
    "        )\n",
    "    except Exception as _e:\n",
    "        raise RuntimeError(f\"[session1/arm][FATAL] 读取 arm JSON 失败: {_e}\") from _e\n",
    "\n",
    "    _arm_cable_raw   = _arm_json.get(\"ARM_CABLE_INITIAL_PROMPTS\", [])\n",
    "    _arm_cable_2_raw = _arm_json.get(\"ARM_CABLE_2_INITIAL_PROMPTS\", [])\n",
    "\n",
    "    _arm_cable_norm = validate_and_normalize_prompt_list(\n",
    "        _arm_cable_raw,\n",
    "        total_frames=TOTAL_FRAMES,\n",
    "        img_w=IMG_WIDTH,\n",
    "        img_h=IMG_HEIGHT,\n",
    "        tag=\"ARM_CABLE_INITIAL_PROMPTS\",\n",
    "        allow_empty=True,\n",
    "    )\n",
    "    _arm_cable_2_norm = []\n",
    "    if ARM_OBJ_ID_2 is not None:\n",
    "        _arm_cable_2_norm = validate_and_normalize_prompt_list(\n",
    "            _arm_cable_2_raw,\n",
    "            total_frames=TOTAL_FRAMES,\n",
    "            img_w=IMG_WIDTH,\n",
    "            img_h=IMG_HEIGHT,\n",
    "            tag=\"ARM_CABLE_2_INITIAL_PROMPTS\",\n",
    "            allow_empty=True,\n",
    "        )\n",
    "        for _p in _arm_cable_2_norm:\n",
    "            if _p[\"obj_id\"] != ARM_OBJ_ID_2:\n",
    "                raise ValueError(\n",
    "                    f\"[session1/arm] ARM_CABLE_2 prompt obj_id={_p['obj_id']} \"\n",
    "                    f\"!= ARM_OBJ_ID_2={ARM_OBJ_ID_2}。请检查 JSON 或配置。\"\n",
    "                )\n",
    "\n",
    "    arm_prompts_norm = _arm_cable_norm + _arm_cable_2_norm\n",
    "\n",
    "    _arm1_frames = sorted({p[\"frame_index\"] for p in _arm_cable_norm})\n",
    "    _arm2_frames = sorted({p[\"frame_index\"] for p in _arm_cable_2_norm})\n",
    "    print(f\"[session1/arm] arm_cable   entries={len(_arm_cable_norm)}  keyframes={_arm1_frames}\")\n",
    "    print(f\"[session1/arm] arm_cable_2 entries={len(_arm_cable_2_norm)}  keyframes={_arm2_frames}\")\n",
    "    print(f\"[session1/arm] total arm prompt entries: {len(arm_prompts_norm)}\")\n",
    "    if len(arm_prompts_norm) == 0:\n",
    "        print(\"[session1/arm][WARN] JSON 存在但无标注点，Session 1 将仅用 text bootstrap。\")\n",
    "    else:\n",
    "        print(\"[session1/arm] arm point prompts loaded. Ready for Session 1 refinement.\")\n",
    "\n",
    "# ============================================================\n",
    "# Session 1 — Arm 分割\n",
    "# Step 1: text bootstrap → 初始双向传播（填充缓存）\n",
    "# Step 2: 若有 arm 点标注，apply_prompt_list → 最终双向传播\n",
    "# ============================================================\n",
    "\n",
    "print(\"[session1/arm] initializing predictor ...\")\n",
    "# gpus_to_use = range(torch.cuda.device_count())\n",
    "gpus_to_use = range(len(CUDA_VISIBLE_DEVICES.split(',')))\n",
    "\n",
    "predictor_arm = build_sam3_video_predictor(\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    gpus_to_use=gpus_to_use,\n",
    "    apply_temporal_disambiguation=APPLY_TEMPORAL_DISAMBIGUATION,\n",
    ")\n",
    "\n",
    "start_response = predictor_arm.handle_request(\n",
    "    request=dict(type=\"start_session\", resource_path=VIDEO_PATH)\n",
    ")\n",
    "session_id_arm = start_response[\"session_id\"]\n",
    "print(f\"[session1/arm] session started: session_id={session_id_arm}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 1: Text bootstrap → 初始双向传播（填充缓存）\n",
    "# ----------------------------------------------------------\n",
    "print(f\"[session1/arm] text bootstrap: frame={ARM_TEXT_BOOTSTRAP_FRAME_INDEX}  prompt={ARM_TEXT_PROMPT!r}\")\n",
    "add_text_prompt(\n",
    "    predictor_obj=predictor_arm,\n",
    "    session_id_value=session_id_arm,\n",
    "    frame_index=ARM_TEXT_BOOTSTRAP_FRAME_INDEX,\n",
    "    text_prompt=ARM_TEXT_PROMPT,\n",
    "    stage_name=\"session1/arm\",\n",
    ")\n",
    "\n",
    "print(\"[session1/arm] propagating (bidirectional, initial pass) ...\")\n",
    "outputs_arm = propagate_bidirectional_and_merge(\n",
    "    predictor_obj=predictor_arm,\n",
    "    session_id_value=session_id_arm,\n",
    "    stage_name=\"session1/arm\",\n",
    ")\n",
    "print(f\"[session1/arm] initial propagation done: {len(outputs_arm)} frames\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Step 2: 若有 arm 点标注，应用后重新传播\n",
    "# ----------------------------------------------------------\n",
    "if arm_prompts_norm:\n",
    "    print(f\"[session1/arm] applying {len(arm_prompts_norm)} arm point prompt entries ...\")\n",
    "    apply_prompt_list(\n",
    "        predictor_obj=predictor_arm,\n",
    "        session_id_value=session_id_arm,\n",
    "        prompt_list=arm_prompts_norm,\n",
    "        stage_name=\"session1/arm_refine\",\n",
    "    )\n",
    "    print(\"[session1/arm] re-propagating after arm point refinement ...\")\n",
    "    outputs_arm = propagate_bidirectional_and_merge(\n",
    "        predictor_obj=predictor_arm,\n",
    "        session_id_value=session_id_arm,\n",
    "        stage_name=\"session1/arm_refine\",\n",
    "    )\n",
    "    print(f\"[session1/arm] refinement done: {len(outputs_arm)} frames\")\n",
    "else:\n",
    "    print(\"[session1/arm] no arm point prompts, skipping refinement (text bootstrap only)\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 校验 ARM_OBJ_ID 是否出现在输出中\n",
    "# ----------------------------------------------------------\n",
    "_arm_ids_found = set()\n",
    "for _fo in outputs_arm.values():\n",
    "    for _oid, _ in iter_object_masks_from_frame_output(_fo):\n",
    "        _arm_ids_found.add(int(_oid))\n",
    "print(f\"[session1/arm] obj_ids in outputs: {sorted(_arm_ids_found)}\")\n",
    "if ARM_OBJ_ID not in _arm_ids_found:\n",
    "    print(\n",
    "        f\"[session1/arm][WARN] ARM_OBJ_ID={ARM_OBJ_ID} not found. \"\n",
    "        f\"Found: {sorted(_arm_ids_found)}. \"\n",
    "        f\"Please update ARM_OBJ_ID in config to match the actual id.\"\n",
    "    )\n",
    "if ARM_OBJ_ID_2 is not None and ARM_OBJ_ID_2 not in _arm_ids_found:\n",
    "    print(\n",
    "        f\"[session1/arm][WARN] ARM_OBJ_ID_2={ARM_OBJ_ID_2} not found in outputs. \"\n",
    "        f\"Left arm may not have been detected. Check arm point annotations.\"\n",
    "    )\n",
    "\n",
    "# 关闭 Session 1；outputs_arm 保留在内存供 Merge 使用\n",
    "print(\"[session1/arm] shutting down predictor ...\")\n",
    "cleanup_resources(predictor_obj=predictor_arm, session_id_value=session_id_arm)\n",
    "predictor_arm = None\n",
    "session_id_arm = None\n",
    "print(f\"[session1/arm] done. outputs_arm preserved ({len(outputs_arm)} frames).\")\n",
    "\n",
    "# ============================================================\n",
    "# Checkpoint: 将 arm union masks 保存到磁盘\n",
    "# 作用：若 Session 2 卡死需重启，可从 checkpoint 加载 arm 结果，跳过重跑 Session 1\n",
    "# ============================================================\n",
    "print(f\"[ckpt/arm] saving pre-dilate arm masks → {CHECKPOINT_ARM_DIR}\")\n",
    "os.makedirs(CHECKPOINT_ARM_DIR, exist_ok=True)\n",
    "_ckpt_w, _ckpt_h = get_frame_size(video_frames_for_vis)\n",
    "for _ckpt_fi in range(TOTAL_FRAMES):\n",
    "    _ckpt_u = np.zeros((_ckpt_h, _ckpt_w), np.uint8)\n",
    "    for _, _ckpt_m in iter_object_masks_from_frame_output(outputs_arm.get(_ckpt_fi, {})):\n",
    "        if isinstance(_ckpt_m, torch.Tensor):\n",
    "            _ckpt_m = _ckpt_m.detach().cpu().numpy()\n",
    "        if _ckpt_m.ndim > 2:\n",
    "            _ckpt_m = np.squeeze(_ckpt_m)\n",
    "        _ckpt_u = np.maximum(_ckpt_u, (_ckpt_m > 0).astype(np.uint8) * 255)\n",
    "    Image.fromarray(_ckpt_u, \"L\").save(os.path.join(CHECKPOINT_ARM_DIR, f\"{_ckpt_fi:05d}.png\"))\n",
    "print(f\"[ckpt/arm] done: {TOTAL_FRAMES} frames → {CHECKPOINT_ARM_DIR}\")\n",
    "\n",
    "# ============================================================\n",
    "# 可视化 Session 1 arm 结果\n",
    "# 检查 arm 掩膜质量，若不满意请调整标注点后重新运行 Session 1\n",
    "# ============================================================\n",
    "visualize_outputs(\n",
    "    outputs_per_frame=outputs_arm,\n",
    "    video_frames=video_frames_for_vis,\n",
    "    stride=VIS_FRAME_STRIDE,\n",
    "    max_plots=VIS_MAX_PLOTS,\n",
    "    title=\"Session 1: Arm Segmentation (text bootstrap + point refinement)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nb1-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理\n",
    "\n",
    "# ============================================================\n",
    "# 防御性清理（重复运行或异常中断后确保资源释放）\n",
    "# ============================================================\n",
    "\n",
    "if predictor_arm is not None:\n",
    "    print('[cleanup] cleaning arm predictor (not yet cleaned)')\n",
    "    cleanup_resources(predictor_obj=predictor_arm, session_id_value=session_id_arm)\n",
    "    predictor_arm = None\n",
    "    session_id_arm = None\n",
    "else:\n",
    "    print('[cleanup] predictor_arm already cleaned')\n",
    "\n",
    "cleanup_process_group()\n",
    "print('[cleanup] all resources released')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}